Thank you for the constructive reviews of our paper. We are pleased that reviewers found our work interesting & relevant to HCI literature. Reviewers listed a number of possible improvements, which we will do as follows:


R2, R3, R4, & R5 request methodological details. We will clarify in the methodology & experiment design sections that:
* The needfinding survey was voluntary & was distributed to students from different disciplines. For the final experiment, participants were recruited from one college. We will clarify these in Section 3.1 & Limitations and Future Work.
* There were 54 participants in the needfinding survey; out of those, 16 were chosen & completed the semi-structured interviews. They are regular (N=10), delayed (N=4), & shiftee students (N=2)[a][b]. They were chosen among participants because they gave unique & unexpected answers.
* A new set of participants was recruited for the contextual inquiry (N=5) & the final experiment (N=42).
* In the contextual inquiry, we asked participants to naturally perform their own respective schedule creation methods using their preferred tools (if any). We observed pain points & workarounds, & asked for suggestions. These insights can be found in Section 3.3. To clarify, we will merge Sections 3.2 & 3.3 into one section & name it Findings.
* In the final experiment, we recruited 14 “cliques” or “groups of friends” with 2–4 members each. Each clique is composed of actual peers that have experience with coordinating schedules with each other. In total, there were 42 participants. We will clarify that the “sets of groups” are cliques. 
* In the experiment design, the 14 cliques are divided equally into 2 groups, the control group & the experimental group. 
* Cliques from both groups did the same set of tasks. The experimental group used the proposed system while the control group was asked to freely use their own respective schedule creation methods using their preferred tools (if any). We will also clarify this in Section 7.2.
* The experimental group was only given a general description of the system before the tasks to observe the intuitiveness of the system for first-time users.


We would like to thank R2 for pointing out that the subject of evaluation in the study could be further clarified. We clarify that the focus of the study is on how SAT solvers can be integrated into a semi-automated system that aids students in scheduling. We defined a taxonomy of preferences through a needfinding study, encoded them into the SAT solver, & designed and evaluated the proposed system (p. 2). SAT solvers have so far been implemented in fully automated systems wherein constraints are defined once at the start, without input from those who will use the schedules. In student scheduling, student preferences are complex and change every semester. Thus, we chose to develop a semi-automated system to test the ecological validity and potential of SAT solvers in handling the differing preferences of students. We understand that the contribution of the SAT solver to the performance differences may have been overemphasized in the results. We also found that interface design elements such as calendar visualization had an impact on comprehension of information (p. 16) and informative feedback contributing to the perceived perspicuity of the system (p. 17). [c]We will highlight these in the Results section to show that the performance differences were attributed to both the SAT solver & various elements of the interface design. 


R4 noted that the novel contributions of our work could be better emphasized through clearer comparisons to previous literature in common domains. Per R4’s recommendation, we will emphasize that in contrast to other scheduling works, such as Achá & Nieuwenhuis and Strichman, our work contributes a system with greater focus on user considerations, through a semi-automated interface that reduces manual effort while maintaining user involvement, along with a more comprehensive evaluation of its effects on user satisfaction, task completion, cognitive load, & stress. 


R2 recommends that we situate our work with suggested references on scheduling interfaces. We have read these references and agree that they can clarify the novelty of our work. We note that our system operates in a different domain (student scheduling) to the systems mentioned in these references, which makes it subject to different design considerations given the specific needs entailed in the use cases in this domain. In contrast to Huh et al., our study concerns participants whose resulting schedules directly affect them (personal academic schedules), and it hence provides additional insights into the incorporation of user control in this context. Our study also provides insights on how decisions involving multiple users in a common environment might be facilitated while accounting for numerous weighted considerations, in contrast to less collaboration-oriented works, such as Oh et al., and scheduling works where preferences are less numerous and/or explicitly defined, such as Kim et al.


Our needfinding echoes similar design considerations from the suggested references:
* User control in automation (Oh et al., Huh et. al)
* Satisfying preferences of one or more users (Kim et al.)
* Use of shared calendar views in collaboration (Tullio et. al)


We will incorporate these references into our paper to supplement our discussion.


We feel that the planned changes above do not require significant alterations to the overall story & are therefore feasible within the revision period. We will address miscellaneous concerns through a full pass.
[a]We have to either define these terms or use a more generic term for these.
[b]These terms were defined in the paper, as a footnote, we can change it into a generic term
[c]this